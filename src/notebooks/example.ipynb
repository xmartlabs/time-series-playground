{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019309,
     "end_time": "2021-01-25T17:44:56.225683",
     "exception": false,
     "start_time": "2021-01-25T17:44:56.206374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. initial Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:44:56.274544Z",
     "iopub.status.busy": "2021-01-25T17:44:56.273844Z",
     "iopub.status.idle": "2021-01-25T17:45:00.930963Z",
     "shell.execute_reply": "2021-01-25T17:45:00.932314Z"
    },
    "papermill": {
     "duration": 4.688814,
     "end_time": "2021-01-25T17:45:00.932549",
     "exception": false,
     "start_time": "2021-01-25T17:44:56.243735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import numpy for number array handling and represent rgb image pixel values\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "#Import and initialize WandB\n",
    "# import wandb\n",
    "\n",
    "#import tensorflow to use any tools needed for deep learning\n",
    "import tensorflow as tf\n",
    "\n",
    "#import keras api needed to implement deep learning techiques\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, BatchNormalization, Conv2D, MaxPool2D, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# from focal_loss import SparseCategoricalFocalLoss\n",
    "\n",
    "#import libraries for visualization of data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Allow charts and graphics to display right below the page of browser setup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversion import ModelConverter\n",
    "\n",
    "from model import MyModel\n",
    "# from examples.wandb_tracker import WandBTracker, TrainTrackingCallback\n",
    "from examples.mlflow_tracker import MLFlowTracker, MLFlowTrainTrackingCallback\n",
    "from metrics import plot_loss, plot_accuracy, print_confusion_matrix\n",
    "from utils import show_worst_preds, crop_resize_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027768,
     "end_time": "2021-01-25T17:45:00.990373",
     "exception": false,
     "start_time": "2021-01-25T17:45:00.962605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Load and Split images along with applying Data Preprocessing and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:45:01.056401Z",
     "iopub.status.busy": "2021-01-25T17:45:01.055577Z",
     "iopub.status.idle": "2021-01-25T17:45:01.785136Z",
     "shell.execute_reply": "2021-01-25T17:45:01.784312Z"
    },
    "papermill": {
     "duration": 0.768071,
     "end_time": "2021-01-25T17:45:01.785335",
     "exception": false,
     "start_time": "2021-01-25T17:45:01.017264",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#paths to the train, validation and test image datasets \n",
    "train_path = '../datasets/kaggle_dataset/images/'\n",
    "valid_path = '../datasets/kaggle_dataset/images/'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "CLASSES = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "\n",
    "tracker = MLFlowTracker(\"trash-classification\")\n",
    "\n",
    "classifier = MyModel(CLASSES, BATCH_SIZE, tracker)\n",
    "classifier.load_dataset(train_path, valid_path)\n",
    "\n",
    "train_batches = classifier.train_batches\n",
    "valid_batches = classifier.valid_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01875,
     "end_time": "2021-01-25T17:45:01.838639",
     "exception": false,
     "start_time": "2021-01-25T17:45:01.819889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Visualization of the images after Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:45:01.885615Z",
     "iopub.status.busy": "2021-01-25T17:45:01.884882Z",
     "iopub.status.idle": "2021-01-25T17:45:01.888921Z",
     "shell.execute_reply": "2021-01-25T17:45:01.888396Z"
    },
    "papermill": {
     "duration": 0.03,
     "end_time": "2021-01-25T17:45:01.889029",
     "exception": false,
     "start_time": "2021-01-25T17:45:01.859029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot images after applying VGG16 data preprocessing method\n",
    "def plotImages(images):\n",
    "    fig, axes = plt.subplots(1, 6, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images, axes):\n",
    "        ax.imshow(img.astype(np.uint8))\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:45:01.929599Z",
     "iopub.status.busy": "2021-01-25T17:45:01.928961Z",
     "iopub.status.idle": "2021-01-25T17:45:02.763823Z",
     "shell.execute_reply": "2021-01-25T17:45:02.764347Z"
    },
    "papermill": {
     "duration": 0.857229,
     "end_time": "2021-01-25T17:45:02.764488",
     "exception": false,
     "start_time": "2021-01-25T17:45:01.907259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)\n",
    "plotImages(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025808,
     "end_time": "2021-01-25T17:45:02.816480",
     "exception": false,
     "start_time": "2021-01-25T17:45:02.790672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Building CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:45:02.877875Z",
     "iopub.status.busy": "2021-01-25T17:45:02.877237Z",
     "iopub.status.idle": "2021-01-25T17:45:06.503631Z",
     "shell.execute_reply": "2021-01-25T17:45:06.503012Z"
    },
    "papermill": {
     "duration": 3.66123,
     "end_time": "2021-01-25T17:45:06.503741",
     "exception": false,
     "start_time": "2021-01-25T17:45:02.842511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the input image size for proposed CNN model\n",
    "classifier.build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030793,
     "end_time": "2021-01-25T17:45:06.952949",
     "exception": false,
     "start_time": "2021-01-25T17:45:06.922156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Compile the Built CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:45:07.027357Z",
     "iopub.status.busy": "2021-01-25T17:45:07.026725Z",
     "iopub.status.idle": "2021-01-25T17:45:07.035494Z",
     "shell.execute_reply": "2021-01-25T17:45:07.034942Z"
    },
    "papermill": {
     "duration": 0.051264,
     "end_time": "2021-01-25T17:45:07.035597",
     "exception": false,
     "start_time": "2021-01-25T17:45:06.984333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile the built CNN model by selecting suitable optimizer and loss function\n",
    "# myFocalLoss = SparseCategoricalFocalLoss(gamma=2)\n",
    "# myFocalLoss = focal_loss(alpha=0.25)\n",
    "\n",
    "classifier.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030276,
     "end_time": "2021-01-25T17:45:07.097660",
     "exception": false,
     "start_time": "2021-01-25T17:45:07.067384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Train the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:45:07.166459Z",
     "iopub.status.busy": "2021-01-25T17:45:07.165838Z",
     "iopub.status.idle": "2021-01-25T17:56:09.487184Z",
     "shell.execute_reply": "2021-01-25T17:56:09.488445Z"
    },
    "papermill": {
     "duration": 662.359554,
     "end_time": "2021-01-25T17:56:09.488723",
     "exception": false,
     "start_time": "2021-01-25T17:45:07.129169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train the model with appropriate number of epochs\n",
    "model_details = classifier.fit(epochs=30)\n",
    "\n",
    "# With VGG16: Epoch 18/18\n",
    "# 143/143 - 35s - loss: 0.3366 - accuracy: 0.8814 - val_loss: 0.3784 - val_accuracy: 0.8645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:56:09.669548Z",
     "iopub.status.busy": "2021-01-25T17:56:09.668403Z",
     "iopub.status.idle": "2021-01-25T17:56:09.679982Z",
     "shell.execute_reply": "2021-01-25T17:56:09.680599Z"
    },
    "papermill": {
     "duration": 0.105985,
     "end_time": "2021-01-25T17:56:09.680755",
     "exception": false,
     "start_time": "2021-01-25T17:56:09.574770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store the losses of training\n",
    "loss = model_details.history['loss']\n",
    "validation_loss = model_details.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:56:09.856889Z",
     "iopub.status.busy": "2021-01-25T17:56:09.855857Z",
     "iopub.status.idle": "2021-01-25T17:56:09.857905Z",
     "shell.execute_reply": "2021-01-25T17:56:09.859525Z"
    },
    "papermill": {
     "duration": 0.094288,
     "end_time": "2021-01-25T17:56:09.859723",
     "exception": false,
     "start_time": "2021-01-25T17:56:09.765435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# store the accuracy of training\n",
    "accuracy = model_details.history['accuracy']\n",
    "validation_accuracy = model_details.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.080179,
     "end_time": "2021-01-25T17:56:10.016782",
     "exception": false,
     "start_time": "2021-01-25T17:56:09.936603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Fine Tune the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:56:10.141892Z",
     "iopub.status.busy": "2021-01-25T17:56:10.140312Z",
     "iopub.status.idle": "2021-01-25T17:56:10.142717Z",
     "shell.execute_reply": "2021-01-25T17:56:10.143310Z"
    },
    "papermill": {
     "duration": 0.061165,
     "end_time": "2021-01-25T17:56:10.143447",
     "exception": false,
     "start_time": "2021-01-25T17:56:10.082282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unfreeze the convolution base of the base model inorder to fine-tune which adapt these pre-trained weights \n",
    "# to work with the new dataset\n",
    "classifier.base_model.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:56:10.387406Z",
     "iopub.status.busy": "2021-01-25T17:56:10.386348Z",
     "iopub.status.idle": "2021-01-25T17:58:36.150100Z",
     "shell.execute_reply": "2021-01-25T17:58:36.150833Z"
    },
    "papermill": {
     "duration": 145.836216,
     "end_time": "2021-01-25T17:58:36.151039",
     "exception": false,
     "start_time": "2021-01-25T17:56:10.314823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train and fine-tune the model with appropriate number of epochs\n",
    "model_details = classifier.fit(epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045805,
     "end_time": "2021-01-25T17:58:36.243627",
     "exception": false,
     "start_time": "2021-01-25T17:58:36.197822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. Visualization of Accuracy and Loss in Training and  Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:58:36.342525Z",
     "iopub.status.busy": "2021-01-25T17:58:36.340772Z",
     "iopub.status.idle": "2021-01-25T17:58:36.343195Z",
     "shell.execute_reply": "2021-01-25T17:58:36.343656Z"
    },
    "papermill": {
     "duration": 0.054282,
     "end_time": "2021-01-25T17:58:36.343781",
     "exception": false,
     "start_time": "2021-01-25T17:58:36.289499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# append the losses to previous stored losses\n",
    "loss.extend(model_details.history['loss'])\n",
    "validation_loss.extend(model_details.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:58:36.444084Z",
     "iopub.status.busy": "2021-01-25T17:58:36.443528Z",
     "iopub.status.idle": "2021-01-25T17:58:36.447603Z",
     "shell.execute_reply": "2021-01-25T17:58:36.446963Z"
    },
    "papermill": {
     "duration": 0.05786,
     "end_time": "2021-01-25T17:58:36.447709",
     "exception": false,
     "start_time": "2021-01-25T17:58:36.389849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# append the accuracy to previous stored accuracy\n",
    "accuracy.extend(model_details.history['accuracy'])\n",
    "validation_accuracy.extend(model_details.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:58:36.554172Z",
     "iopub.status.busy": "2021-01-25T17:58:36.552802Z",
     "iopub.status.idle": "2021-01-25T17:58:36.763492Z",
     "shell.execute_reply": "2021-01-25T17:58:36.763975Z"
    },
    "papermill": {
     "duration": 0.269871,
     "end_time": "2021-01-25T17:58:36.764093",
     "exception": false,
     "start_time": "2021-01-25T17:58:36.494222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the training and validation losses\n",
    "plot_loss(loss, validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-25T17:58:36.872839Z",
     "iopub.status.busy": "2021-01-25T17:58:36.871372Z",
     "iopub.status.idle": "2021-01-25T17:58:37.063336Z",
     "shell.execute_reply": "2021-01-25T17:58:37.063864Z"
    },
    "papermill": {
     "duration": 0.251957,
     "end_time": "2021-01-25T17:58:37.063995",
     "exception": false,
     "start_time": "2021-01-25T17:58:36.812038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the training and validation accuracy\n",
    "plot_accuracy(accuracy, validation_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finish tracker run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.tracker.finish_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(valid_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confusion_matrix(classifier.model, valid_batches, Y_pred, CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print problematic cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_worst_preds(valid_batches, Y_pred, CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Model to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.049791,
     "end_time": "2021-01-25T17:58:37.163896",
     "exception": false,
     "start_time": "2021-01-25T17:58:37.114105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert model to TF Lite\n",
    "converter = ModelConverter(classifier.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.to_tflite('../models/model.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.to_tflite_fp16('../models/model_fp16.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "  for data in tf.data.Dataset.from_generator(lambda: train_batches, (tf.float32, tf.float32)).batch(1).take(100):\n",
    "    yield [data[0][0]]\n",
    "\n",
    "converter.to_tflite_quantized('../models/model_int8.tflite', representative_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.to_tfjs('../models/js/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/saved_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in valid_batches[0][0][0]:\n",
    "#     print(i.shape)\n",
    "img = valid_batches[0][0][0]\n",
    "plotImages([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img1 = Image.open('../datasets/kaggle_dataset/images/cardboard/cardboard10.jpg')\n",
    "img = crop_resize_image(img1)\n",
    "img = np.array(img)\n",
    "img = img.astype(np.float32)\n",
    "\n",
    "# img = tf.keras.applications.mobilenet_v3.preprocess_input(img.astype(np.float32))\n",
    "img = np.expand_dims(img, axis=0)\n",
    "print(img.shape, img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter('../models/model_fp16.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = img\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "print(CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "duration": 827.092531,
   "end_time": "2021-01-25T17:58:38.463459",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-01-25T17:44:51.370928",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
